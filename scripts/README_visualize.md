# eBPF Performance Visualization Script

## Overview

`visualize_ebpf_performance.py` creates comprehensive visualizations of eBPF agent performance data from CSV files generated by prow.

## Usage

```bash
python3 scripts/visualize_ebpf_performance.py <csv_file> <prow_id> [--output <output_file>]
```

### Arguments

- `csv_file`: Path to CSV file containing performance data such as `https://gcsweb-ci.apps.ci.l2s4.p1.openshiftapps.com/gcs/test-platform-results/pr-logs/pull/netobserv_netobserv-ebpf-agent/824/pull-ci-netobserv-netobserv-ebpf-agent-main-ebpf-node-density-heavy-25nodes/1985348508604960768/artifacts/ebpf-node-density-heavy-25nodes/openshift-qe-orion/artifacts/data-netobserv-perf-node-density-heavy-AWS-25w.csv`
- `prow_id`: Prow ID of the target run to compare against previous runs such as `1985348508604960768`
- `--output`, `-o`: (Optional) Output PNG file path (default: `perf/ebpf_performance_visualization.png`)

### Examples

```bash
# Basic usage
python3 scripts/visualize_ebpf_performance.py data.csv 1985348508604960768

# Specify custom output file
python3 scripts/visualize_ebpf_performance.py data.csv 1985348508604960768 --output custom_output.png

# With full paths
python3 scripts/visualize_ebpf_performance.py /path/to/data.csv 1985348508604960768 -o /path/to/output.png
```

## Requirements

- Python 3
- matplotlib
- numpy

Install dependencies:
```bash
pip3 install matplotlib numpy
```

## Output

The script generates an 8-panel visualization (5 rows Ã— 2 columns) showing:

**Row 1:**
1. **Flows Processed Over Time** - Scatter plot with previous average line
2. **Flows Processed Comparison** - Bar chart comparing min/avg/max vs current

**Row 2:**
3. **CPU Usage Over Time** - CPU usage trends with previous average line
4. **Memory Usage Over Time** - RSS memory usage trends with previous average line

**Row 3:**
5. **CPU Efficiency** - Flows per minute per core scatter plot with efficiency trend line
6. **Memory Efficiency** - Flows per minute per MB scatter plot with efficiency trend line

**Row 4:**
7. **Efficiency Comparison** - Percentage change bar chart (CPU and Memory efficiency vs previous average), full width spanning both columns

**Row 5:**
8. **Summary Statistics** - Comprehensive text panel split into 3 columns:
   - **Column 1**: Flows metrics (Flows Processed, Flows Per Minute)
   - **Column 2**: Resource usage (CPU Usage, Memory RSS)
   - **Column 3**: Efficiency metrics and Dropped Flows information

## Metrics Visualized

- **Flows Processed**: Total flows and flows per minute
- **CPU Usage**: Resource consumption (cores) over time
- **Memory Usage**: RSS memory consumption (GB) over time
- **Efficiency Metrics**:
  - **CPU Efficiency**: Flows per minute per core (scatter plot + percentage change)
  - **Memory Efficiency**: Flows per minute per MB (scatter plot + percentage change)
- **Dropped Flows**: Reliability indicator (zero is ideal) - shown in summary panel only

## Notes

- The script compares the target prow ID against all previous runs in the CSV
- Efficiency calculations use rate-based metrics (flows per minute) for accurate comparison
- Memory efficiency is calculated per MB (not GB) for more granular analysis
- Efficiency comparison shows percentage change from previous average (green = improvement, orange = regression)
- All plots include trend lines and reference averages for easy comparison
- Dropped flows information is displayed in the summary panel (not as a separate plot)
- Summary statistics are organized into 3 columns for better readability
- Output is saved at 300 DPI for high-quality visualization
- By default, output is saved to `perf/` folder (created automatically if it doesn't exist)
- The `perf/` folder is ignored by git (added to `.gitignore`)

